{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datapath_manager import DataPathManager, ITWDataPathManager\n",
    "from trainers import MachineLearningModelTrainer, BranchNeuralNetworkTrainer\n",
    "from dataloader import EmbeddingDataLoader\n",
    "from evaluators import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id = 'ltkhiem'\n",
    "# dates = ['2022-10-16', '2022-10-17', '2022-10-18', '2022-10-20', '2022-10-21', '2022-10-22']\n",
    "user_id = 'lzhou'\n",
    "dates = ['2022-09-11', '2022-09-12', '2022-09-13', '2022-09-14', '2022-09-15', '2022-09-16']\n",
    "# user_id = 'tlduyen'\n",
    "# dates = ['2022-09-27', '2022-09-28', '2022-09-30', '2022-10-01', '2022-10-02', '2022-10-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.abspath(f'./models/{user_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-based model for the targeted user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_dataset_name = 'DCU_NVT_EXP2'\n",
    "window_size = 60\n",
    "window_shift = 0.25\n",
    "signal_type = 'bvp_eda_temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_manager = DataPathManager(lab_dataset_name)\n",
    "lab_feature_folder_path = os.path.dirname(dp_manager.get_feature_path(user_id, signal_type, window_size, window_shift))\n",
    "ground_truth_path = os.path.join(lab_feature_folder_path, 'ground_truth.npy')\n",
    "tasks_index_path = os.path.join(lab_feature_folder_path, 'tasks_index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_features = []\n",
    "signals = ['bvp', 'eda', 'temp']\n",
    "for signal in signals:\n",
    "    signal_path = os.path.join(lab_feature_folder_path, f'{signal}.npy')\n",
    "    signal_data = np.load(signal_path)\n",
    "    lab_features.append(signal_data)\n",
    "lab_features = np.concatenate(lab_features, axis=1)\n",
    "tasks_index = np.load(tasks_index_path)\n",
    "ground_truth = np.load(ground_truth_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test lab-based model\n",
    "def split_train_test(indices, test_size: float = 0.3):\n",
    "        \"\"\"\n",
    "        Split train and test data for subject-dependent model training:\n",
    "            - Train_data: (1 - test_size) * number of data of a class\n",
    "            - Test_data: test_size * number of data of a class \n",
    "        NOTE: This means that this approach of data splitting simulate the real-life situation \n",
    "        where the test data is the segment of data that is recorded later after we have the train data.\n",
    "        \"\"\"\n",
    "        cut_point = int((1 - test_size) * len(indices))\n",
    "        train_indices = indices[:cut_point].tolist()\n",
    "        test_indices = indices[cut_point:].tolist()\n",
    "        return train_indices, test_indices\n",
    "\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "VALID_SIZE = 0.1\n",
    "indices = np.arange(lab_features.shape[0]) # The indices of the lab-based features\n",
    "train_indices, valid_indices, test_indices = [], [], []\n",
    "for _, task_test_index in LeaveOneGroupOut().split(indices, y=None, groups=tasks_index):\n",
    "    task_train_indices, task_test_indices = split_train_test(indices[task_test_index], test_size = TEST_SIZE)\n",
    "    task_train_indices, task_valid_indices = split_train_test(indices[task_train_indices], test_size = VALID_SIZE)\n",
    "    train_indices += task_train_indices\n",
    "    valid_indices += task_valid_indices\n",
    "    test_indices += task_test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train Deep-Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = lab_features[train_indices], ground_truth[train_indices]\n",
    "X_valid, y_valid = lab_features[valid_indices], ground_truth[valid_indices]\n",
    "X_test, y_test = lab_features[test_indices], ground_truth[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = EmbeddingDataLoader(X_train, y_train)\n",
    "validate_dataloader = EmbeddingDataLoader(X_valid, y_valid)\n",
    "test_dataloader = EmbeddingDataLoader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load deep model configuration\n",
    "user_model_saved_path = os.path.join(f'{model_path}/lab_deep_fusion.pth')\n",
    "config_path = os.path.join(\n",
    "    os.path.dirname(os.getcwd()), \n",
    "    'models', 'model_config', \n",
    "    f'branchnn_sensor_combination_{signal_type}.yaml'\n",
    ")\n",
    "config_dict = yaml.safe_load(open(config_path, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL\n"
     ]
    }
   ],
   "source": [
    "df_clf = BranchNeuralNetworkTrainer('./logs.txt', \n",
    "    user_model_saved_path, \n",
    "    config_dict, \n",
    "    target_metrics=['balanced_accuracy', 'f1'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clf.train(train_dataloader, validate_dataloader, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7399913904433921, 'balanced_accuracy': 0.6873414337788578, 'precision': 0.7622950819672131, 'recall': 0.868, 'f1': 0.8117206982543641}\n"
     ]
    }
   ],
   "source": [
    "y_pred = df_clf.predict(test_dataloader)\n",
    "print(Evaluator().evaluate(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train ExtraTreesClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(bootstrap=True, class_weight=&#x27;balanced&#x27;, max_depth=8,\n",
       "                     min_samples_leaf=8, n_estimators=500, n_jobs=-1,\n",
       "                     oob_score=True, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(bootstrap=True, class_weight=&#x27;balanced&#x27;, max_depth=8,\n",
       "                     min_samples_leaf=8, n_estimators=500, n_jobs=-1,\n",
       "                     oob_score=True, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, class_weight='balanced', max_depth=8,\n",
       "                     min_samples_leaf=8, n_estimators=500, n_jobs=-1,\n",
       "                     oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train = np.concatenate([lab_features[train_indices], lab_features[valid_indices]], axis=0)\n",
    "# # y_train = np.concatenate([ground_truth[train_indices], ground_truth[valid_indices]], axis=0)\n",
    "# X_test, y_test = lab_features[test_indices], ground_truth[test_indices]\n",
    "\n",
    "et_clf = ExtraTreesClassifier(\n",
    "    n_estimators = 500,\n",
    "    random_state = 0, \n",
    "    n_jobs = -1, \n",
    "    max_features = 'sqrt', \n",
    "    max_depth = 8, \n",
    "    min_samples_split = 2, \n",
    "    min_samples_leaf = 8,\n",
    "    oob_score = True, \n",
    "    bootstrap = True, \n",
    "    class_weight = 'balanced'\n",
    ")\n",
    "et_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9817204301075269, 'balanced_accuracy': 0.9858333333333333, 'precision': 1.0, 'recall': 0.9716666666666667, 'f1': 0.9856297548605241}\n"
     ]
    }
   ],
   "source": [
    "y_pred = et_clf.predict(X_valid)\n",
    "print(Evaluator().evaluate(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8932414980628498, 'balanced_accuracy': 0.8858003240178209, 'precision': 0.9224021592442645, 'recall': 0.9113333333333333, 'f1': 0.9168343393695507}\n"
     ]
    }
   ],
   "source": [
    "y_pred = et_clf.predict(X_test)\n",
    "print(Evaluator().evaluate(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nvtu/Stress-Detection-Processor/experiment_scripts/models/ltkhiem/lab_et_clf.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'model': et_clf, 'scaler': None}\n",
    "joblib.dump(data, os.path.join(model_path, 'lab_et_clf.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=50000, n_jobs=-1,\n",
       "                   random_state=0, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=50000, n_jobs=-1,\n",
       "                   random_state=0, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=50000, n_jobs=-1,\n",
       "                   random_state=0, solver='saga')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train = std_scaler.fit_transform(np.concatenate([lab_features[train_indices], lab_features[valid_indices]], axis=0))\n",
    "y_train = np.concatenate([ground_truth[train_indices], ground_truth[valid_indices]], axis=0)\n",
    "X_valid, y_valid = std_scaler.transform(lab_features[valid_indices]), ground_truth[valid_indices]\n",
    "X_test, y_test = std_scaler.transform(lab_features[test_indices]), ground_truth[test_indices]\n",
    "\n",
    "lr_clf = LogisticRegression(\n",
    "    random_state = 0,\n",
    "    class_weight = 'balanced',\n",
    "    n_jobs = -1,\n",
    "    solver = 'saga',\n",
    "    max_iter = 50000,\n",
    ")\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9978494623655914, 'balanced_accuracy': 0.9983333333333333, 'precision': 1.0, 'recall': 0.9966666666666667, 'f1': 0.9983305509181971}\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_clf.predict(X_valid)\n",
    "print(Evaluator().evaluate(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7619457597933706, 'balanced_accuracy': 0.6983090319967598, 'precision': 0.7626178591236827, 'recall': 0.9166666666666666, 'f1': 0.8325764456554647}\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_clf.predict(X_test)\n",
    "print(Evaluator().evaluate(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nvtu/Stress-Detection-Processor/experiment_scripts/models/ltkhiem/lab_lr_clf.pkl']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'model': lr_clf, 'scaler': std_scaler}\n",
    "joblib.dump(data, os.path.join(model_path, 'lab_lr_clf.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-the-wild model for the targeted user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_dataset_name = 'DCU_EXP2_ITW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(user_id: str, date: str,):\n",
    "    dataset_path = ITWDataPathManager(itw_dataset_name).get_dataset_path()\n",
    "\n",
    "    user_date_feature_path = os.path.join(dataset_path, 'features', user_id, date)\n",
    "    feature_path = os.path.join(user_date_feature_path, 'X.npy')\n",
    "    gt_path = os.path.join(user_date_feature_path, 'y.npy')\n",
    "\n",
    "    feat = np.nan_to_num(np.load(feature_path))[:, :72]\n",
    "    gt = np.load(gt_path)\n",
    "    return feat, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 16619, 1.0: 1242})\n",
      "Counter({0.0: 30000, 1.0: 7224})\n",
      "Counter({0.0: 39579, 1.0: 6050})\n",
      "Counter({0.0: 48606})\n",
      "Counter({0.0: 23292, 1.0: 5447})\n",
      "Counter({0.0: 7408, 1.0: 2120})\n"
     ]
    }
   ],
   "source": [
    "def get_moments_features_and_labels(user_id: str, date: str,):\n",
    "    dataset_path = ITWDataPathManager(itw_dataset_name).get_dataset_path()\n",
    "\n",
    "    user_date_feature_path = os.path.join(dataset_path, 'features', user_id, date)\n",
    "    feature_path = os.path.join(user_date_feature_path, 'X_moment.npy')\n",
    "    gt_path = os.path.join(user_date_feature_path, 'y_moment.npy')\n",
    "\n",
    "    feat = np.nan_to_num(np.load(feature_path))[:, :72]\n",
    "    gt = np.load(gt_path)\n",
    "    return feat, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 16619, 1.0: 1242})\n",
      "Counter({0.0: 30000, 1.0: 7224})\n",
      "Counter({0.0: 39579, 1.0: 6050})\n",
      "Counter({0.0: 48606})\n",
      "Counter({0.0: 23292, 1.0: 5447})\n",
      "Counter({0.0: 7408, 1.0: 2120})\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "feat_dates = [get_features_and_labels(user_id, date) for date in dates]\n",
    "for x in feat_dates:\n",
    "    print(Counter(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 642, 1: 49})\n",
      "Counter({1: 513, 0: 125})\n",
      "Counter({1: 780, 0: 199})\n",
      "Counter({0: 331, 1: 300})\n",
      "Counter({1: 563, 0: 501})\n",
      "Counter({1: 166, 0: 100})\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "moments_feat_dates = [get_moments_features_and_labels(user_id, date) for date in dates]\n",
    "for x in moments_feat_dates:\n",
    "    print(Counter(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Apply lab-based model to in-the-wild data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_itw = np.concatenate([x[0] for x in feat_dates], axis=0)\n",
    "y_test_itw = np.concatenate([x[1] for x in feat_dates], axis=0)\n",
    "X_test_moment_itw = np.concatenate([x[0] for x in moments_feat_dates], axis=0)\n",
    "y_test_moment_itw = np.concatenate([x[1] for x in moments_feat_dates], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_test_dataloader = EmbeddingDataLoader(X_test_itw, y_test_itw)\n",
    "itw_moment_test_dataloader = EmbeddingDataLoader(X_test_moment_itw, y_test_moment_itw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL\n"
     ]
    }
   ],
   "source": [
    "itw_user_model_saved_path = os.path.abspath(f'{model_path}/itw_deep_fusion.pth')\n",
    "itw_df_clf = BranchNeuralNetworkTrainer('./logs.txt',\n",
    "    itw_user_model_saved_path,\n",
    "    config_dict,\n",
    "    target_metrics=['balanced_accuracy', 'f1'],\n",
    "    pretrained_model_path = user_model_saved_path\n",
    ")\n",
    "itw_et_clf = joblib.load(os.path.join(model_path, 'lab_et_clf.pkl'))['model']\n",
    "itw_lr_clf = joblib.load(os.path.join(model_path, 'lab_lr_clf.pkl'))['model']\n",
    "std_scaler = joblib.load(os.path.join(model_path, 'lab_lr_clf.pkl'))['scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deep Fusion ---\n",
      "{'accuracy': 0.6056762995303513, 'balanced_accuracy': 0.5728674240878092, 'precision': 0.15543277595526808, 'recall': 0.5299551691346285, 'f1': 0.24036723627998688}\n",
      "--- Extra Trees ---\n",
      "{'accuracy': 0.5223762840708578, 'balanced_accuracy': 0.5947644795360743, 'precision': 0.1554158202586691, 'recall': 0.6894443689716071, 'f1': 0.25365276643953155}\n",
      "--- Logistic Regression ---\n",
      "{'accuracy': 0.6167271719255599, 'balanced_accuracy': 0.5744603678724267, 'precision': 0.15760750027493675, 'recall': 0.5191776479644976, 'f1': 0.24180876754510847}\n"
     ]
    }
   ],
   "source": [
    "# Lab-based Deep Fusion model applied to ITW data\n",
    "print(\"--- Deep Fusion ---\")\n",
    "y_pred_itw = itw_df_clf.predict(itw_test_dataloader)\n",
    "print(Evaluator().evaluate(y_test_itw, y_pred_itw))\n",
    "print(\"--- Extra Trees ---\")\n",
    "y_pred_itw = itw_et_clf.predict(X_test_itw)\n",
    "print(Evaluator().evaluate(y_test_itw, y_pred_itw))\n",
    "print(\"--- Logistic Regression ---\")\n",
    "y_pred_itw = itw_lr_clf.predict(std_scaler.transform(X_test_itw))\n",
    "print(Evaluator().evaluate(y_test_itw, y_pred_itw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deep Fusion ---\n",
      "{'accuracy': 0.553025641025641, 'balanced_accuracy': 0.5581207989146115, 'precision': 0.2297003907946157, 'recall': 0.5663811563169164, 'f1': 0.3268458449181341}\n",
      "--- Extra Trees ---\n",
      "{'accuracy': 0.4886153846153846, 'balanced_accuracy': 0.5713830661790316, 'precision': 0.22905804657629475, 'recall': 0.7055674518201285, 'f1': 0.3458409866176856}\n",
      "--- Logistic Regression ---\n",
      "{'accuracy': 0.558974358974359, 'balanced_accuracy': 0.5589408442622906, 'precision': 0.23097345132743363, 'recall': 0.5588865096359743, 'f1': 0.3268628678772699}\n"
     ]
    }
   ],
   "source": [
    "# Lab-based Deep Fusion model applied to ITW data\n",
    "print(\"--- Deep Fusion ---\")\n",
    "y_pred_itw = itw_df_clf.predict(itw_moment_test_dataloader)\n",
    "print(Evaluator().evaluate(y_test_moment_itw, y_pred_itw))\n",
    "print(\"--- Extra Trees ---\")\n",
    "y_pred_itw = itw_et_clf.predict(X_test_moment_itw)\n",
    "print(Evaluator().evaluate(y_test_moment_itw, y_pred_itw))\n",
    "print(\"--- Logistic Regression ---\")\n",
    "y_pred_itw = itw_lr_clf.predict(std_scaler.transform(X_test_moment_itw))\n",
    "print(Evaluator().evaluate(y_test_moment_itw, y_pred_itw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fine-tune the lab-based model to adapt to the in-the-wild data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first 3 days for training\n",
    "X_train = np.concatenate([x[0] for x in feat_dates[:3]])\n",
    "y_train = np.concatenate([x[1] for x in feat_dates[:3]]).astype(int)\n",
    "# Use the last 3 days for testing\n",
    "X_test = np.concatenate([x[0] for x in feat_dates[3:]])\n",
    "y_test = np.concatenate([x[1] for x in feat_dates[3:]]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune Deep-Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_train_dataloader = EmbeddingDataLoader(X_train, y_train)\n",
    "itw_test_dataloader = EmbeddingDataLoader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL\n"
     ]
    }
   ],
   "source": [
    "itw_df_clf = BranchNeuralNetworkTrainer('./logs.txt', \n",
    "    itw_user_model_saved_path, \n",
    "    config_dict, \n",
    "    target_metrics=['balanced_accuracy', 'f1'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7303650155974813, 'balanced_accuracy': 0.6183724672509305, 'precision': 0.15770841428139706, 'recall': 0.48275406369763446, 'f1': 0.237748128864302}\n"
     ]
    }
   ],
   "source": [
    "# itw_df_clf.train(itw_train_dataloader, itw_test_dataloader, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7358788115985404, 'balanced_accuracy': 0.6280868447019602, 'precision': 0.1643530644316396, 'recall': 0.4975551737808907, 'f1': 0.24708777686628386}\n"
     ]
    }
   ],
   "source": [
    "y_pred_itw = itw_df_clf.predict(itw_test_dataloader)\n",
    "print(Evaluator().evaluate(y_test, y_pred_itw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Re-train ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train ExtraTreesClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(bootstrap=True, class_weight=&#x27;balanced&#x27;, max_depth=8,\n",
       "                     min_samples_leaf=8, n_estimators=500, n_jobs=-1,\n",
       "                     oob_score=True, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(bootstrap=True, class_weight=&#x27;balanced&#x27;, max_depth=8,\n",
       "                     min_samples_leaf=8, n_estimators=500, n_jobs=-1,\n",
       "                     oob_score=True, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, class_weight='balanced', max_depth=8,\n",
       "                     min_samples_leaf=8, n_estimators=500, n_jobs=-1,\n",
       "                     oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itw_et_clf = ExtraTreesClassifier(\n",
    "    n_estimators = 500,\n",
    "    random_state = 0, \n",
    "    n_jobs = -1, \n",
    "    max_features = 'sqrt', \n",
    "    max_depth = 8, \n",
    "    min_samples_split = 2, \n",
    "    min_samples_leaf = 8,\n",
    "    oob_score = True, \n",
    "    bootstrap = True, \n",
    "    class_weight = 'balanced'\n",
    ")\n",
    "itw_et_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6796933454583127, 'balanced_accuracy': 0.6655729083471642, 'precision': 0.16316962058989792, 'recall': 0.6484736355226642, 'f1': 0.26073326248671624}\n"
     ]
    }
   ],
   "source": [
    "y_pred_itw = itw_et_clf.predict(X_test)\n",
    "print(Evaluator().evaluate(y_test, y_pred_itw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nvtu/Stress-Detection-Processor/experiment_scripts/models/ltkhiem/itw_et_clf.pkl']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'model': itw_et_clf, 'scaler': None}\n",
    "joblib.dump(data, os.path.join(model_path, 'itw_et_clf.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvtu/.conda/envs/huawei_nvtu/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, n_jobs=-1,\n",
       "                   random_state=0, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, n_jobs=-1,\n",
       "                   random_state=0, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, n_jobs=-1,\n",
       "                   random_state=0, solver='saga')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itw_lr_clf = LogisticRegression(\n",
    "    random_state = 0,\n",
    "    class_weight = 'balanced',\n",
    "    n_jobs = -1,\n",
    "    solver = 'saga',\n",
    "    max_iter = 1000,\n",
    ")\n",
    "itw_lr_clf.fit(scaler.fit_transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7397119933696316, 'balanced_accuracy': 0.6241493667423496, 'precision': 0.16376882849863675, 'recall': 0.48420774415224, 'f1': 0.2447561790247161}\n"
     ]
    }
   ],
   "source": [
    "y_pred_itw = itw_lr_clf.predict(scaler.transform(X_test))\n",
    "print(Evaluator().evaluate(y_test, y_pred_itw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nvtu/Stress-Detection-Processor/experiment_scripts/models/ltkhiem/itw_lr_clf.pkl']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'model': itw_lr_clf, 'scaler': std_scaler}\n",
    "joblib.dump(data, os.path.join(model_path, 'itw_lr_clf.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the in-the-wild model with lifelog image moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first 3 days for training\n",
    "X_train_moments = np.concatenate([x[0] for x in moments_feat_dates[:3]])\n",
    "y_train_moments = np.concatenate([x[1] for x in moments_feat_dates[:3]]).astype(int)\n",
    "# Use the last 3 days for testing\n",
    "X_test_moments = np.concatenate([x[0] for x in moments_feat_dates[3:]])\n",
    "y_test_moments = np.concatenate([x[1] for x in moments_feat_dates[3:]]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitw_train_dataloader = EmbeddingDataLoader(X_train_moments, y_train_moments)\n",
    "mitw_test_dataloader = EmbeddingDataLoader(X_test_moments, y_test_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.659427966101695, 'balanced_accuracy': 0.623865233947255, 'precision': 0.21994134897360704, 'recall': 0.5747126436781609, 'f1': 0.3181336161187699}\n"
     ]
    }
   ],
   "source": [
    "y_preds = itw_df_clf.predict(mitw_test_dataloader)\n",
    "# y_preds = np.where(y_preds > df_thresholdOpt, 1, 0)\n",
    "print(Evaluator().evaluate(y_test_moments, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.576271186440678, 'balanced_accuracy': 0.6383443189284277, 'precision': 0.20610687022900764, 'recall': 0.7241379310344828, 'f1': 0.3208828522920204}\n"
     ]
    }
   ],
   "source": [
    "y_preds = itw_et_clf.predict(X_test_moments)\n",
    "# y_preds = np.where(y_preds > thresholdOpt, 1, 0)\n",
    "print(Evaluator().evaluate(y_test_moments, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds_prob = itw_df_clf.predict_proba(mitw_test_dataloader)\n",
    "et_preds_prob = itw_et_clf.predict_proba(X_test_moments)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_prob = 0.05 * np.array(df_preds_prob) + 0.95 * np.array(et_preds_prob)\n",
    "preds = np.where(preds_prob > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5911016949152542, 'balanced_accuracy': 0.6501659025025491, 'precision': 0.21388577827547592, 'recall': 0.7318007662835249, 'f1': 0.3310225303292894}\n"
     ]
    }
   ],
   "source": [
    "print(Evaluator().evaluate(y_test_moments, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('stress')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37ebc3d14ab14189c4eae9bca0430f788ed6f529827f083fec73cc217c56eda2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
