{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/stress/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import __init__\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import joblib\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datapath_manager import DataPathManager, ITWDataPathManager\n",
    "from trainers import MachineLearningModelTrainer, BranchNeuralNetworkTrainer\n",
    "from dataloader import EmbeddingDataLoader\n",
    "from evaluators import Evaluator\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'ltkhiem'\n",
    "dates = ['2022-10-16', '2022-10-17', '2022-10-18', '2022-10-20', '2022-10-21', '2022-10-22']\n",
    "feature_lists = ['min_temp', 'mean_temp', 'max_temp', 'eda_slope', 'corr', 'std_HRV', 'HRV_SD2', 'HRV_RMSSD', 'std_HR', 'total_power']\n",
    "# user_id = 'lzhou'\n",
    "# dates = ['2022-09-11', '2022-09-12', '2022-09-13', '2022-09-14', '2022-09-15', '2022-09-16']\n",
    "# feature_lists = ['mean_temp', 'eda_slope', 'HRV_HTI', 'range_temp', 'nn20', 'kurtosis_relativeRRI', 'temp_slope', 'skewness_scr', 'mean_first_grad', 'num_scr_peaks']\n",
    "# user_id = 'tlduyen'\n",
    "# dates = ['2022-09-27', '2022-09-28', '2022-09-30', '2022-10-01', '2022-10-02', '2022-10-03']\n",
    "# feature_lists = ['min_temp', 'max_temp', 'mean_temp', 'temp_slope', 'skewness_HRV', 'mean_HR', 'std_HR', 'nn20', 'eda_slope', 'rms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.abspath(f'./models/{user_id}')\n",
    "feature_names = [line.strip() for line in open('feature_names.txt', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_by_features(feature_lists, X, Y, Z = None, T = None, labels = ['Stress', 'Relax']):\n",
    "    \"\"\"\n",
    "    X: feature matrix\n",
    "    Y: feature matrix\n",
    "    X and Y should have the same number of rows\n",
    "    \"\"\"\n",
    "    # nrows, ncols = 12, 6\n",
    "    nrows, ncols = 2, 5\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=(20, 8))\n",
    "\n",
    "    indices = [feature_names.index(feature) for feature in feature_lists]\n",
    "    num_features = len(feature_lists)\n",
    "    for i in range(num_features):\n",
    "        data = [X[:, indices[i]], Y[:, indices[i]]]\n",
    "        if Z is not None:\n",
    "            if Z.shape[0] == 0:\n",
    "                data.append([])\n",
    "            else:\n",
    "                data.append(Z[:, indices[i]])\n",
    "        if T is not None:\n",
    "            data.append(T[:, indices[i]])\n",
    "        x, y = i // ncols, i % ncols\n",
    "        ax[x, y].boxplot(data, labels=labels)\n",
    "        ax[x, y].set_title(feature_lists[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-based model for the targeted user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_dataset_name = 'DCU_NVT_EXP2'\n",
    "window_size = 60\n",
    "window_shift = 0.25\n",
    "signal_type = 'bvp_eda_temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_manager = DataPathManager(lab_dataset_name)\n",
    "lab_feature_folder_path = os.path.dirname(dp_manager.get_feature_path(user_id, signal_type, window_size, window_shift))\n",
    "ground_truth_path = os.path.join(lab_feature_folder_path, 'ground_truth.npy')\n",
    "tasks_index_path = os.path.join(lab_feature_folder_path, 'tasks_index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_features = []\n",
    "signals = ['bvp', 'eda', 'temp']\n",
    "for signal in signals:\n",
    "    signal_path = os.path.join(lab_feature_folder_path, f'{signal}.npy')\n",
    "    signal_data = np.load(signal_path)\n",
    "    lab_features.append(signal_data)\n",
    "lab_features = np.concatenate(lab_features, axis=1)\n",
    "tasks_index = np.load(tasks_index_path)\n",
    "ground_truth = np.load(ground_truth_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test lab-based model\n",
    "def split_train_test(indices, test_size: float = 0.3):\n",
    "        \"\"\"\n",
    "        Split train and test data for subject-dependent model training:\n",
    "            - Train_data: (1 - test_size) * number of data of a class\n",
    "            - Test_data: test_size * number of data of a class \n",
    "        NOTE: This means that this approach of data splitting simulate the real-life situation \n",
    "        where the test data is the segment of data that is recorded later after we have the train data.\n",
    "        \"\"\"\n",
    "        cut_point = int((1 - test_size) * len(indices))\n",
    "        train_indices = indices[:cut_point].tolist()\n",
    "        test_indices = indices[cut_point:].tolist()\n",
    "        return train_indices, test_indices\n",
    "\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "VALID_SIZE = 0.1\n",
    "indices = np.arange(lab_features.shape[0]) # The indices of the lab-based features\n",
    "train_indices, valid_indices, test_indices = [], [], []\n",
    "for _, task_test_index in LeaveOneGroupOut().split(indices, y=None, groups=tasks_index):\n",
    "    task_train_indices, task_test_indices = split_train_test(indices[task_test_index], test_size = TEST_SIZE)\n",
    "    task_train_indices, task_valid_indices = split_train_test(indices[task_train_indices], test_size = VALID_SIZE)\n",
    "    train_indices += task_train_indices\n",
    "    valid_indices += task_valid_indices\n",
    "    test_indices += task_test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train Deep-Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = lab_features[train_indices], ground_truth[train_indices]\n",
    "X_valid, y_valid = lab_features[valid_indices], ground_truth[valid_indices]\n",
    "X_test, y_test = lab_features[test_indices], ground_truth[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = EmbeddingDataLoader(X_train, y_train)\n",
    "validate_dataloader = EmbeddingDataLoader(X_valid, y_valid)\n",
    "test_dataloader = EmbeddingDataLoader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load deep model configuration\n",
    "user_model_saved_path = os.path.join(f'{model_path}/lab_deep_fusion.pth')\n",
    "config_path = os.path.join(\n",
    "    os.path.dirname(os.getcwd()), \n",
    "    'models', 'model_config', \n",
    "    f'branchnn_sensor_combination_{signal_type}.yaml'\n",
    ")\n",
    "config_dict = yaml.safe_load(open(config_path, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL\n"
     ]
    }
   ],
   "source": [
    "df_clf = BranchNeuralNetworkTrainer('./logs.txt', \n",
    "    user_model_saved_path, \n",
    "    config_dict, \n",
    "    target_metrics=['balanced_accuracy', 'precision', 'recall'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clf.train(train_dataloader, validate_dataloader, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df_clf.predict(test_dataloader)\n",
    "print(Evaluator().evaluate(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train ExtraTreesClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.concatenate([lab_features[train_indices], lab_features[valid_indices]], axis=0)\n",
    "# # y_train = np.concatenate([ground_truth[train_indices], ground_truth[valid_indices]], axis=0)\n",
    "# X_test, y_test = lab_features[test_indices], ground_truth[test_indices]\n",
    "\n",
    "et_clf = ExtraTreesClassifier(\n",
    "    n_estimators = 500,\n",
    "    random_state = 0, \n",
    "    n_jobs = -1, \n",
    "    max_features = 'sqrt', \n",
    "    max_depth = 8, \n",
    "    min_samples_split = 2, \n",
    "    min_samples_leaf = 8,\n",
    "    oob_score = True, \n",
    "    bootstrap = True, \n",
    "    class_weight = 'balanced'\n",
    ")\n",
    "et_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = et_clf.predict(X_valid)\n",
    "print(Evaluator().evaluate(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = et_clf.predict(X_test)\n",
    "print(Evaluator().evaluate(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.TreeExplainer(et_clf)\n",
    "# shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values[1], X_train, feature_names=feature_names, plot_type='violin', max_display=10, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values[1], X_train, feature_names=feature_names, plot_type='bar', max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'model': et_clf, 'scaler': None}\n",
    "joblib.dump(data, os.path.join(model_path, 'lab_et_clf.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train = std_scaler.fit_transform(np.concatenate([lab_features[train_indices], lab_features[valid_indices]], axis=0))\n",
    "y_train = np.concatenate([ground_truth[train_indices], ground_truth[valid_indices]], axis=0)\n",
    "X_valid, y_valid = std_scaler.transform(lab_features[valid_indices]), ground_truth[valid_indices]\n",
    "X_test, y_test = std_scaler.transform(lab_features[test_indices]), ground_truth[test_indices]\n",
    "\n",
    "lr_clf = LogisticRegression(\n",
    "    random_state = 0,\n",
    "    class_weight = 'balanced',\n",
    "    n_jobs = -1,\n",
    "    solver = 'saga',\n",
    "    max_iter = 1000,\n",
    ")\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_clf.predict(X_train)\n",
    "print(Evaluator().evaluate(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_clf.predict(X_valid)\n",
    "print(Evaluator().evaluate(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_clf.predict(X_test)\n",
    "print(Evaluator().evaluate(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considered_features = feature_names.copy()\n",
    "# remove_features = []\n",
    "# THRESHOLD = 5\n",
    "# X = X_train.copy()\n",
    "# while True:\n",
    "#     changed = False\n",
    "#     vif = pd.DataFrame()\n",
    "#     indices = [feature_names.index(f) for f in considered_features]\n",
    "#     _X = X[:, indices]\n",
    "#     vif[\"VIF Factor\"] = [variance_inflation_factor(_X, i) for i in range(len(indices))]\n",
    "#     vif['features'] = considered_features\n",
    "#     f = vif.round(1).sort_values('VIF Factor', ascending=False).iloc[0]\n",
    "#     if f['VIF Factor'] > THRESHOLD:\n",
    "#         remove_features.append(f['features'])\n",
    "#         considered_features.remove(f['features'])\n",
    "#         changed = True\n",
    "#         print(f'Removing {f}')\n",
    "#     if changed == False:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = [feature_names.index(f) for f in considered_features]\n",
    "# X = X[:, indices]\n",
    "# lr_clf.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_v = X_valid[:, indices]\n",
    "# X_t = X_test[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_preds = lr_clf.predict(X_v)\n",
    "# print(Evaluator().evaluate(y_valid, y_preds))\n",
    "# y_preds = lr_clf.predict(X_t)\n",
    "# print(Evaluator().evaluate(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.LinearExplainer(lr_clf, X)\n",
    "# shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values, X, feature_names=considered_features, plot_type='violin', max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values, X, feature_names=considered_features, plot_type='bar', max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'model': lr_clf, 'scaler': std_scaler}\n",
    "joblib.dump(data, os.path.join(model_path, 'lab_lr_clf.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-the-wild model for the targeted user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_dataset_name = 'DCU_EXP2_ITW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(user_id: str, date: str,):\n",
    "    dataset_path = ITWDataPathManager(itw_dataset_name).get_dataset_path()\n",
    "\n",
    "    user_date_feature_path = os.path.join(dataset_path, 'features', user_id, date)\n",
    "    feature_path = os.path.join(user_date_feature_path, 'X.npy')\n",
    "    gt_path = os.path.join(user_date_feature_path, 'y.npy')\n",
    "\n",
    "    feat = np.nan_to_num(np.load(feature_path))[:, :72]\n",
    "    gt = np.load(gt_path)\n",
    "    return feat, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moments_features_and_labels(user_id: str, date: str,):\n",
    "    dataset_path = ITWDataPathManager(itw_dataset_name).get_dataset_path()\n",
    "\n",
    "    user_date_feature_path = os.path.join(dataset_path, 'features', user_id, date)\n",
    "    feature_path = os.path.join(user_date_feature_path, 'X_moment.npy')\n",
    "    gt_path = os.path.join(user_date_feature_path, 'y_moment.npy')\n",
    "\n",
    "    feat = np.nan_to_num(np.load(feature_path))[:, :72]\n",
    "    gt = np.load(gt_path)\n",
    "    return feat, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 7250, 1.0: 560})\n",
      "Counter({0.0: 4793, 1.0: 3250})\n",
      "Counter({0.0: 11270, 1.0: 2740})\n",
      "Counter({0.0: 8185})\n",
      "Counter({0.0: 4497, 1.0: 2460})\n",
      "Counter({0.0: 2768, 1.0: 960})\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "feat_dates = [get_features_and_labels(user_id, date) for date in dates]\n",
    "for x in feat_dates:\n",
    "    print(Counter(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 725, 1: 56})\n",
      "Counter({0: 480, 1: 325})\n",
      "Counter({0: 1127, 1: 274})\n",
      "Counter({0: 819})\n",
      "Counter({0: 450, 1: 246})\n",
      "Counter({0: 277, 1: 96})\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "moments_feat_dates = [get_moments_features_and_labels(user_id, date) for date in dates]\n",
    "for x in moments_feat_dates:\n",
    "    print(Counter(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Apply lab-based model to in-the-wild data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_itw = np.concatenate([x[0] for x in feat_dates], axis=0)\n",
    "y_test_itw = np.concatenate([x[1] for x in feat_dates], axis=0)\n",
    "X_test_moment_itw = np.concatenate([x[0] for x in moments_feat_dates], axis=0)\n",
    "y_test_moment_itw = np.concatenate([x[1] for x in moments_feat_dates], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_stress = X_train[y_train == 1]\n",
    "# X_train_relax = X_train[y_train == 0]\n",
    "# X_test_stress = X_test_moment_itw[y_test_moment_itw == 1]\n",
    "# X_test_relax = X_test_moment_itw[y_test_moment_itw == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot_by_features(feature_lists, X_train_stress, X_train_relax, X_test_stress, X_test_relax, labels = ['Train_S', 'Train_R', 'ITW_S', 'ITW_R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_test_dataloader = EmbeddingDataLoader(X_test_itw, y_test_itw)\n",
    "itw_moment_test_dataloader = EmbeddingDataLoader(X_test_moment_itw, y_test_moment_itw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL\n"
     ]
    }
   ],
   "source": [
    "itw_user_model_saved_path = os.path.abspath(f'{model_path}/itw_deep_fusion.pth')\n",
    "itw_df_clf = BranchNeuralNetworkTrainer('./logs.txt',\n",
    "    itw_user_model_saved_path,\n",
    "    config_dict,\n",
    "    target_metrics=['balanced_accuracy', 'f1'],\n",
    "    pretrained_model_path = user_model_saved_path\n",
    ")\n",
    "itw_et_clf = joblib.load(os.path.join(model_path, 'lab_et_clf.pkl'))['model']\n",
    "itw_lr_clf = joblib.load(os.path.join(model_path, 'lab_lr_clf.pkl'))['model']\n",
    "std_scaler = joblib.load(os.path.join(model_path, 'lab_lr_clf.pkl'))['scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deep Fusion ---\n",
      "{'accuracy': 0.5466521658834875, 'balanced_accuracy': 0.5319332542942659, 'precision': 0.22736472810686817, 'recall': 0.5070210631895687, 'f1': 0.31394590566096325}\n",
      "--- Extra Trees ---\n",
      "{'accuracy': 0.4862413559600271, 'balanced_accuracy': 0.560825434795732, 'precision': 0.23812006813362532, 'recall': 0.6870611835506519, 'f1': 0.35366703668327437}\n",
      "--- Logistic Regression ---\n",
      "{'accuracy': 0.5465085260501098, 'balanced_accuracy': 0.5353446079797062, 'precision': 0.22957909755662564, 'recall': 0.5164493480441325, 'f1': 0.3178591271066115}\n"
     ]
    }
   ],
   "source": [
    "# Lab-based Deep Fusion model applied to ITW data\n",
    "print(\"--- Deep Fusion ---\")\n",
    "y_pred_itw = itw_df_clf.predict(itw_test_dataloader)\n",
    "print(Evaluator().evaluate(y_test_itw, y_pred_itw))\n",
    "print(\"--- Extra Trees ---\")\n",
    "y_pred_itw = itw_et_clf.predict(X_test_itw)\n",
    "print(Evaluator().evaluate(y_test_itw, y_pred_itw))\n",
    "print(\"--- Logistic Regression ---\")\n",
    "y_pred_itw = itw_lr_clf.predict(std_scaler.transform(X_test_itw))\n",
    "print(Evaluator().evaluate(y_test_itw, y_pred_itw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deep Fusion ---\n",
      "{'accuracy': 0.5462564102564103, 'balanced_accuracy': 0.5318685556411369, 'precision': 0.22721149528513696, 'recall': 0.5075225677031093, 'f1': 0.31389578163771714}\n",
      "--- Extra Trees ---\n",
      "{'accuracy': 0.4867692307692308, 'balanced_accuracy': 0.5615411215596248, 'precision': 0.2384428223844282, 'recall': 0.6880641925777332, 'f1': 0.354155911202891}\n",
      "--- Logistic Regression ---\n",
      "{'accuracy': 0.5456410256410257, 'balanced_accuracy': 0.5370703394350147, 'precision': 0.23053097345132742, 'recall': 0.522567703109328, 'f1': 0.3199263125575683}\n"
     ]
    }
   ],
   "source": [
    "# Lab-based Deep Fusion model applied to ITW data\n",
    "print(\"--- Deep Fusion ---\")\n",
    "y_pred_itw = itw_df_clf.predict(itw_moment_test_dataloader)\n",
    "print(Evaluator().evaluate(y_test_moment_itw, y_pred_itw))\n",
    "print(\"--- Extra Trees ---\")\n",
    "y_pred_itw = itw_et_clf.predict(X_test_moment_itw)\n",
    "print(Evaluator().evaluate(y_test_moment_itw, y_pred_itw))\n",
    "print(\"--- Logistic Regression ---\")\n",
    "y_pred_itw = itw_lr_clf.predict(std_scaler.transform(X_test_moment_itw))\n",
    "print(Evaluator().evaluate(y_test_moment_itw, y_pred_itw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.TreeExplainer(itw_et_clf)\n",
    "# shap_values = explainer.shap_values(X_test_moment_itw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values[1], X_test_moment_itw, feature_names=feature_names, plot_type='violin', max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values[1], X_test_moment_itw, feature_names=feature_names, plot_type='bar', max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.TreeExplainer(lr_clf)\n",
    "# shap_values = explainer.shap_values(std_scaler.transform(X_test_moment_itw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fine-tune the lab-based model to adapt to the in-the-wild data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first 3 days for training\n",
    "X_train = np.concatenate([x[0] for x in feat_dates[:3]])\n",
    "y_train = np.concatenate([x[1] for x in feat_dates[:3]]).astype(int)\n",
    "# Use the last 3 days for testing\n",
    "X_test = np.concatenate([x[0] for x in feat_dates[3:]])\n",
    "y_test = np.concatenate([x[1] for x in feat_dates[3:]]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune Deep-Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_train_dataloader = EmbeddingDataLoader(X_train, y_train)\n",
    "itw_test_dataloader = EmbeddingDataLoader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_user_model_saved_path = os.path.abspath(f'{model_path}/itw_deep_fusion.pth')\n",
    "itw_df_clf = BranchNeuralNetworkTrainer('./logs.txt', \n",
    "    itw_user_model_saved_path, \n",
    "    config_dict, \n",
    "    target_metrics=['balanced_accuracy', 'precision', 'recall'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itw_df_clf.train(itw_train_dataloader, itw_test_dataloader, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_itw = itw_df_clf.predict(itw_test_dataloader)\n",
    "print(Evaluator().evaluate(y_test, y_pred_itw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Re-train ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train ExtraTreesClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_et_clf = ExtraTreesClassifier(\n",
    "    n_estimators = 500,\n",
    "    random_state = 0, \n",
    "    n_jobs = -1, \n",
    "    max_features = 'sqrt', \n",
    "    max_depth = 8, \n",
    "    min_samples_split = 2, \n",
    "    min_samples_leaf = 8,\n",
    "    # oob_score = True, \n",
    "    # bootstrap = True, \n",
    "    class_weight = 'balanced'\n",
    ")\n",
    "itw_et_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_itw = itw_et_clf.predict(X_test)\n",
    "print(Evaluator().evaluate(y_test, y_pred_itw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'model': itw_et_clf, 'scaler': None}\n",
    "joblib.dump(data, os.path.join(model_path, 'itw_et_clf.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_lr_clf = LogisticRegression(\n",
    "    random_state = 0,\n",
    "    class_weight = 'balanced',\n",
    "    n_jobs = -1,\n",
    "    solver = 'saga',\n",
    "    max_iter = 3000,\n",
    ")\n",
    "itw_lr_clf.fit(scaler.fit_transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_itw = itw_lr_clf.predict(scaler.transform(X_test))\n",
    "print(Evaluator().evaluate(y_test, y_pred_itw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'model': itw_lr_clf, 'scaler': scaler}\n",
    "joblib.dump(data, os.path.join(model_path, 'itw_lr_clf.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the in-the-wild model with lifelog image moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first 3 days for training\n",
    "X_train_moments = np.concatenate([x[0] for x in moments_feat_dates[:3]])\n",
    "y_train_moments = np.concatenate([x[1] for x in moments_feat_dates[:3]]).astype(int)\n",
    "# Use the last 3 days for testing\n",
    "X_test_moments = np.concatenate([x[0] for x in moments_feat_dates[3:]])\n",
    "y_test_moments = np.concatenate([x[1] for x in moments_feat_dates[3:]]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitw_train_dataloader = EmbeddingDataLoader(X_train_moments, y_train_moments)\n",
    "mitw_test_dataloader = EmbeddingDataLoader(X_test_moments, y_test_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = itw_df_clf.predict(mitw_train_dataloader)\n",
    "print(Evaluator().evaluate(y_train_moments, y_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = itw_df_clf.predict(mitw_test_dataloader)\n",
    "# y_preds = np.where(y_preds > df_thresholdOpt, 1, 0)\n",
    "print(Evaluator().evaluate(y_test_moments, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = itw_et_clf.predict(X_test_moments)\n",
    "# y_preds = np.where(y_preds > thresholdOpt, 1, 0)\n",
    "print(Evaluator().evaluate(y_test_moments, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.TreeExplainer(itw_et_clf)\n",
    "# shap_values = explainer.shap_values(X_test_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_shap_values = explainer.shap_values(X_train_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(train_shap_values[1], X_train_moments, feature_names=feature_names, plot_type='violin', max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values[1], X_test_moments, feature_names=feature_names, plot_type='violin', max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = itw_lr_clf.predict(scaler.transform(X_test_moments))\n",
    "# y_preds = np.where(y_preds > thresholdOpt, 1, 0)\n",
    "print(Evaluator().evaluate(y_test_moments, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.LinearExplainer(itw_lr_clf, scaler.transform(X_train_moments))\n",
    "# shap_values = explainer.shap_values(scaler.transform(X_test_moments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values, scaler.transform(X_test_moments), feature_names=feature_names, plot_type='bar', max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = np.concatenate([X_train_moments, X_test_moments])\n",
    "all_labels = np.concatenate([y_train_moments, y_test_moments])\n",
    "mitw = EmbeddingDataLoader(all, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = itw_df_clf.predict(mitw)\n",
    "print(Evaluator().evaluate(all_labels, y_preds))\n",
    "y_preds = itw_et_clf.predict(all)\n",
    "print(Evaluator().evaluate(all_labels, y_preds))\n",
    "y_preds = itw_lr_clf.predict(scaler.transform(all))\n",
    "print(Evaluator().evaluate(all_labels, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_preds_prob = itw_df_clf.predict_proba(mitw_test_dataloader)\n",
    "# et_preds_prob = itw_et_clf.predict_proba(X_test_moments)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_prob = 0.05 * np.array(df_preds_prob) + 0.95 * np.array(et_preds_prob)\n",
    "# preds = np.where(preds_prob > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Evaluator().evaluate(y_test_moments, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('stress')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37ebc3d14ab14189c4eae9bca0430f788ed6f529827f083fec73cc217c56eda2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
