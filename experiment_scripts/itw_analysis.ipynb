{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/stress/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import __init__\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from datapath_manager import ITWDataPathManager, DataPathManager\n",
    "from date_time_utils import get_date_time_from_float, convert_utc_to_local_time\n",
    "from trainers import MachineLearningModelTrainer, BranchNeuralNetworkTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import EmbeddingDataLoader\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score\n",
    "import yaml, torch\n",
    "from collections import Counter\n",
    "from combine_features_itw import ITWFeatureCombiner\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'DCU_EXP2_ITW'\n",
    "user_id = 'nvtu'\n",
    "# user_id = 'tlduyen'\n",
    "user_id = 'ntnhu'\n",
    "# user_id = 'nmduy'\n",
    "# date = '2022-09-02'\n",
    "# date = '2022-09-05'\n",
    "date = '2022-09-06'\n",
    "date = '2022-09-08'\n",
    "\n",
    "trained_dataset_name = 'DCU_NVT_EXP2'\n",
    "dl_model_name = 'branch_neural_network'\n",
    "ml_model_name = 'extra_trees'\n",
    "model_type = 'dependent'\n",
    "window_size = 60\n",
    "window_shift = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = ITWDataPathManager(dataset_name).get_dataset_path()\n",
    "user_date_path = os.path.join(dataset_path, 'data', user_id, date, 'Lifelog')\n",
    "stress_path = os.path.join(user_date_path, 'Stress')\n",
    "relaxed_path = os.path.join(user_date_path, 'Relaxed')\n",
    "low_stress_path = os.path.join(user_date_path, 'LowStress')\n",
    "\n",
    "user_date_feature_path = os.path.join(dataset_path, 'features', user_id, date)\n",
    "feature_path = os.path.join(user_date_feature_path, 'bvp_eda_temp.npy')\n",
    "metadata_path = os.path.join(user_date_feature_path, 'metadata.csv')\n",
    "labels_path = os.path.join(user_date_feature_path, 'stress_state.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and metadata\n",
    "features = np.load(feature_path)\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "# y_test = np.load(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(image_paths, rows, cols):\n",
    "    fig, axes = plt.subplots(nrows = rows, ncols = cols, figsize = (20, 10))\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            index = i * rows + j\n",
    "            img = plt.imread(image_paths[index])\n",
    "            # frame_index = os.path.basename(image_paths[index])\n",
    "            # frame_index = '-'.join(image_paths[index].split('/')[-2:])\n",
    "            frame_index = image_paths[index].split('/')[-2]\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].set_title(frame_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moments_indices(moments, metadata):\n",
    "    moments = [convert_utc_to_local_time(moment).timestamp() for moment in moments]\n",
    "    indices = metadata.loc[metadata['date_time'].isin(moments)].index.tolist()\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_moments(moments, features, metadata):\n",
    "    indices = get_moments_indices(moments, metadata)\n",
    "    return features[indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_images = sorted([os.path.join(stress_path, image_name) for image_name in os.listdir(stress_path)])\n",
    "relaxed_images = sorted([os.path.join(relaxed_path, image_name) for image_name in os.listdir(relaxed_path)])\n",
    "# low_stress_images = sorted([os.path.join(relaxed_path, image_name) for image_name in os.listdir(low_stress_path)])\n",
    "# # Merge relaxed with low stress\n",
    "# relaxed_images.extend(low_stress_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_images(stress_images[:12], 3, 4)\n",
    "# X_test = features\n",
    "# y_test = [0 for _ in range(X_test.shape[0] - 1)]\n",
    "# y_test.append(1)\n",
    "# y_test = np.array(y_test).astype(np.int64)\n",
    "# test_dataloader = EmbeddingDataLoader(X_test, y_test)\n",
    "features_index = [i for i in range(72) if i < 30 or i >= 66]\n",
    "# features_index = [i for i in range(72)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_moments = [os.path.basename(os.path.splitext(image_name)[0]) for image_name in stress_images]\n",
    "relaxed_moments = [os.path.basename(os.path.splitext(image_name)[0]) for image_name in relaxed_images]\n",
    "\n",
    "stress_features = get_features_from_moments(stress_moments, features, metadata)\n",
    "relaxed_features = get_features_from_moments(relaxed_moments, features, metadata)\n",
    "X_test, y_test = np.concatenate((stress_features, relaxed_features), axis=0)[:, features_index], np.concatenate((np.ones(len(stress_features)), np.zeros(len(relaxed_features))), axis=0)\n",
    "y_test = y_test.astype(int)\n",
    "test_dataloader = EmbeddingDataLoader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(model_name):\n",
    "    ds_path_manager = DataPathManager(trained_dataset_name)\n",
    "    user_model_saved_path = ds_path_manager.get_saved_model_path(user_id, model_name, model_type, window_size, window_shift)\n",
    "    if model_name == 'branch_neural_network':\n",
    "        config_path = os.path.join(os.path.dirname(os.getcwd()), 'models', 'model_config', 'branchnn_sensor_combination.yaml')\n",
    "        config_dict = yaml.safe_load(open(config_path, 'r'))\n",
    "        model = BranchNeuralNetworkTrainer('.', user_model_saved_path, config_dict, target_metrics=['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1'])\n",
    "    else:\n",
    "        model = MachineLearningModelTrainer(user_model_saved_path, model_name, eval_mode = True, target_metrics = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_name, dataloader):\n",
    "    y_test = dataloader.dataset.ground_truth\n",
    "    model = get_pretrained_model(model_name)\n",
    "    print(model.predict_and_evaluate(dataloader))\n",
    "    # ConfusionMatrixDisplay.from_predictions(y_test, model.predict(dataloader), display_labels=['Relaxed', 'Stress'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL\n",
      "{'accuracy': 0.537117903930131, 'balanced_accuracy': 0.43909486510008705, 'precision': 0.12154696132596685, 'recall': 0.29333333333333333, 'f1': 0.17187499999999997}\n"
     ]
    }
   ],
   "source": [
    "evaluate(dl_model_name, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PRETRAINED MODEL\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/DATA/nvtu/PhD/stress_data/DCU_NVT_EXP2/models/60_0.25/dependent/extra_trees/ntnhu_extra_trees_dependent_60_0.25.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B136.206.48.13/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m evaluate(ml_model_name, test_dataloader)\n",
      "\u001b[1;32m/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb Cell 14\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model_name, dataloader)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B136.206.48.13/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(model_name, dataloader):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B136.206.48.13/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     y_test \u001b[39m=\u001b[39m dataloader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mground_truth\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B136.206.48.13/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     model \u001b[39m=\u001b[39m get_pretrained_model(model_name)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B136.206.48.13/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mpredict_and_evaluate(dataloader))\n",
      "\u001b[1;32m/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb Cell 14\u001b[0m in \u001b[0;36mget_pretrained_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B136.206.48.13/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     model \u001b[39m=\u001b[39m BranchNeuralNetworkTrainer(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, user_model_saved_path, config_dict, target_metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbalanced_accuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B136.206.48.13/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B136.206.48.13/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     model \u001b[39m=\u001b[39m MachineLearningModelTrainer(user_model_saved_path, model_name, eval_mode \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, target_metrics \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbalanced_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B136.206.48.13/home/nvtu/PhD_Work/ExperimentProtocol2/stress_detection/experiment_scripts/itw_analysis.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/PhD_Work/ExperimentProtocol2/stress_detection/models/trainers.py:207\u001b[0m, in \u001b[0;36mMachineLearningModelTrainer.__init__\u001b[0;34m(self, saved_model_path, method, target_metrics, random_state, eval_mode)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m eval_mode \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLOAD PRETRAINED MODEL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__std_scaler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load_model()\n\u001b[1;32m    208\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__std_scaler \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__std_scaler \u001b[39m=\u001b[39m StandardScaler()\n",
      "File \u001b[0;32m~/PhD_Work/ExperimentProtocol2/stress_detection/models/trainers.py:217\u001b[0m, in \u001b[0;36mMachineLearningModelTrainer.__load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__load_model\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 217\u001b[0m     data \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msaved_model_path)\n\u001b[1;32m    218\u001b[0m     model \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    219\u001b[0m     std_scaler \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mstd_scaler\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mstd_scaler\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m data \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/nmduy/anaconda3/envs/stress/lib/python3.9/site-packages/joblib/numpy_pickle.py:579\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    577\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    578\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    580\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[1;32m    581\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    582\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    583\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    584\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/DATA/nvtu/PhD/stress_data/DCU_NVT_EXP2/models/60_0.25/dependent/extra_trees/ntnhu_extra_trees_dependent_60_0.25.joblib'"
     ]
    }
   ],
   "source": [
    "evaluate(ml_model_name, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_pretrained_model(dl_model_name)\n",
    "y_pred = model.predict(test_dataloader)\n",
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_indices = get_moments_indices(stress_moments, metadata)\n",
    "relaxed_indices = get_moments_indices(relaxed_moments, metadata)\n",
    "info_stress = metadata.loc[stress_indices]\n",
    "info_relaxed = metadata.loc[relaxed_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = [i for i in range(len(y_pred)) if y_pred[i] == 1 and y_test[i] == 1]\n",
    "FN = [i for i in range(len(y_pred)) if y_pred[i] == 0 and y_test[i] == 1]\n",
    "FP = [i for i in range(len(y_pred)) if y_pred[i] == 1 and y_test[i] == 0]\n",
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_stress = np.array(info_stress['date_time_str'].tolist())\n",
    "info_relaxed = np.array(info_relaxed['date_time_str'].tolist())\n",
    "info = np.concatenate((info_stress, info_relaxed), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info[TP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info[FN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info[FP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_pretrained_model(dl_model_name)\n",
    "test_dataloader = EmbeddingDataLoader(features, y_test)\n",
    "model.predict_and_evaluate(test_dataloader)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=['Relaxed', 'Stress'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = ExtraTreesClassifier(\n",
    "#     n_estimators = 500,\n",
    "#     random_state = 0, \n",
    "#     n_jobs = -1, \n",
    "#     max_features = 'sqrt', \n",
    "#     max_depth = 8, \n",
    "#     min_samples_split = 2, \n",
    "#     min_samples_leaf = 8,\n",
    "#     oob_score = True, \n",
    "#     bootstrap = True, \n",
    "#     class_weight = 'balanced'\n",
    "# )\n",
    "m = KNeighborsClassifier(n_neighbors=5, weights='distance', n_jobs=-1)\n",
    "m.fit(features, y_test)\n",
    "y_pred = m.predict(features)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(os.path.join(user_date_feature_path, 'X.npy'))\n",
    "y_test = np.load(os.path.join(user_date_feature_path, 'y.npy'))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_pretrained_model(dl_model_name)\n",
    "y_pred = model.predict(test_dataloader)\n",
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = [convert_utc_to_local_time(moment).timestamp() for moment in stress_moments]\n",
    "stressed = []\n",
    "for i, moment in enumerate(moments):\n",
    "    if len(metadata[metadata['date_time'] == moment]) > 0:\n",
    "        stressed.append(stress_images[i])\n",
    "indices = [i for i in range(len(y_pred)) if y_pred[i] == 1]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(stressed[:12], 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = len(y_pred)\n",
    "images = np.array([*stress_images, *relaxed_images])\n",
    "diff_indices = [i for i in range(num_points) if y_pred[i] != y_test[i]]\n",
    "diff_images = images[diff_indices]\n",
    "diff_images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y = np.zeros(features.shape[0])\n",
    "_test_dataloader = EmbeddingDataLoader(features, _y)\n",
    "_y_pred = model.predict(_test_dataloader)\n",
    "Counter(_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_images(diff_images[:100], 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------- SESSION TEST ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = '20220906_204400'\n",
    "user_id = 'nmduy'\n",
    "date = '2022-09-06'\n",
    "model_name = 'logistic_regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_feat_combiner = ITWFeatureCombiner(dataset_name)\n",
    "features = itw_feat_combiner.combine_session_features(user_id, date, session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = features\n",
    "y_test = np.zeros(X_test.shape[0])\n",
    "test_dataloader = EmbeddingDataLoader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ml_model_name, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\n",
    "    1662649363.73,\n",
    "1662649523.59,\n",
    "1662652170.25,\n",
    "1662652360.69\n",
    "]\n",
    "for x in a: \n",
    "    b = get_date_time_from_float(x)\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('stress')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37ebc3d14ab14189c4eae9bca0430f788ed6f529827f083fec73cc217c56eda2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
