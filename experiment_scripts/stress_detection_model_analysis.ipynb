{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/stress/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import __init__\n",
    "from data_processing.data_splitter import DataSplitter\n",
    "from data_processing.datapath_manager import DataPathManager\n",
    "from data_processing.dataloader import DatasetLoader, EmbeddingDataLoader\n",
    "from models.trainers import MachineLearningModelTrainer\n",
    "from tqdm import tqdm\n",
    "from models.evaluators import Evaluator\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import datetime\n",
    "import mlflow\n",
    "import lightgbm as lgb\n",
    "mlflow.set_tracking_uri('http://localhost:5010')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'DCU_NVT_EXP2'\n",
    "model_type = 'dependent'\n",
    "strategy = 'lgb'\n",
    "WINDOW_SIZE = 60\n",
    "WINDOW_SHIFT = 0.25\n",
    "DEFAULT_SIGNAL = 'eda'\n",
    "SAMPLING_RATE = 4\n",
    "random_state = 0\n",
    "TEST_SIZE = 0.3\n",
    "target_metrics = ['accuracy', 'balanced_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.log_field('model_type', model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path_manager = DataPathManager(dataset_name)\n",
    "ds_splitter = DataSplitter(dataset_name, model_type, TEST_SIZE)\n",
    "data = DatasetLoader(dataset_name).load_dataset_data()\n",
    "\n",
    "# saved_log_path = ds_path_manager.get_log_path(strategy, model_type, WINDOW_SIZE, WINDOW_SHIFT)\n",
    "# print(saved_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 361.12it/s]\n"
     ]
    }
   ],
   "source": [
    "tasks_indices = defaultdict(dict)\n",
    "\n",
    "index = 0\n",
    "for user_id in tqdm(data[DEFAULT_SIGNAL].keys()):\n",
    "    for task_id, signal_data in data[DEFAULT_SIGNAL][user_id].items():\n",
    "\n",
    "        tasks_indices[user_id][task_id] = []\n",
    "\n",
    "        len_signal = len(signal_data)\n",
    "        step = int(WINDOW_SHIFT * SAMPLING_RATE)\n",
    "        first_iter = int(WINDOW_SIZE * SAMPLING_RATE)\n",
    "\n",
    "        for current_iter in range(first_iter, len_signal, step):\n",
    "            previous_iter = current_iter - first_iter\n",
    "            tasks_indices[user_id][task_id].append(index)\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cgurrin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [00:00<00:09,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.8583953241232731, 'balanced_accuracy': 0.8596049855777524}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.8583953241232731, 'balanced_accuracy': 0.8596049855777524}\n",
      "ltkhiem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2/11 [00:01<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.8209342560553633, 'balanced_accuracy': 0.7942415076779897}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.8209342560553633, 'balanced_accuracy': 0.7942415076779897}\n",
      "lttnga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [00:02<00:05,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.7595738554563778, 'balanced_accuracy': 0.710581194422612}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.7595738554563778, 'balanced_accuracy': 0.710581194422612}\n",
      "lzhou\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [00:02<00:04,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "nmduy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5/11 [00:03<00:03,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.8293525179856115, 'balanced_accuracy': 0.7926613386990193}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.8293525179856115, 'balanced_accuracy': 0.7926613386990193}\n",
      "ntnhu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6/11 [00:04<00:03,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.911976911976912, 'balanced_accuracy': 0.8848375636699849}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.911976911976912, 'balanced_accuracy': 0.8848375636699849}\n",
      "nvtu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7/11 [00:04<00:02,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.7732256203115984, 'balanced_accuracy': 0.7367077863944471}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.7732256203115984, 'balanced_accuracy': 0.7367077863944471}\n",
      "pmnguyet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8/11 [00:05<00:01,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.62784588441331, 'balanced_accuracy': 0.5975424169471641}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.62784588441331, 'balanced_accuracy': 0.5975424169471641}\n",
      "qmboi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9/11 [00:05<00:01,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.9408369408369408, 'balanced_accuracy': 0.9195304005321603}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.9408369408369408, 'balanced_accuracy': 0.9195304005321603}\n",
      "tkvan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10/11 [00:06<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.8712557603686636, 'balanced_accuracy': 0.8305325239364327}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.8712557603686636, 'balanced_accuracy': 0.8305325239364327}\n",
      "tlduyen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:07<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation Results: {'accuracy': 1.0, 'balanced_accuracy': 1.0}\n",
      "->>> Validation Evaluation Results: {'accuracy': 0.7494239631336406, 'balanced_accuracy': 0.6996956168831169}\n",
      "-----------------------------------------------------------------------------------------\n",
      "{'accuracy': 0.7494239631336406, 'balanced_accuracy': 0.6996956168831169}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds_splitter.reset()\n",
    "\n",
    "current_datetime = datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S.%f')\n",
    "# experiment_id = mlflow.create_experiment(name = dataset_name)\n",
    "experiment_id = mlflow.get_experiment_by_name(dataset_name).experiment_id\n",
    "\n",
    "\n",
    "for _ in tqdm(range(ds_splitter.num_subjects)):\n",
    "    data = ds_splitter.next()\n",
    "    X_train, y_train, X_test, y_test, target_user = data\n",
    "    print(target_user)\n",
    "\n",
    "    train_embedding_dl = EmbeddingDataLoader(X_train, y_train)\n",
    "    validation_embedding_dl = EmbeddingDataLoader(X_test, y_test)\n",
    "    \n",
    "    saved_model_path = ds_path_manager.get_saved_model_path(target_user, strategy, model_type, WINDOW_SIZE, WINDOW_SHIFT)\n",
    "    model = MachineLearningModelTrainer(strategy, target_metrics = target_metrics, random_state = random_state) \n",
    "\n",
    "    eval_results = model.train(train_embedding_dl, validation_embedding_dl)\n",
    "    print(eval_results)\n",
    "    \n",
    "    # params = {\n",
    "    #     'user_id': target_user,\n",
    "    #     'model_type': model_type,\n",
    "    #     'strategy': strategy,\n",
    "    # }\n",
    "    # tags = {\n",
    "    #     'window_size': WINDOW_SIZE,\n",
    "    #     'window_shift': WINDOW_SHIFT,\n",
    "    #     'test_size': TEST_SIZE,\n",
    "    # }\n",
    "\n",
    "    # with mlflow.start_run(\n",
    "    #     experiment_id=experiment_id,\n",
    "    #     run_name = f'{target_user}',\n",
    "    #     # tags = tags\n",
    "    # ):\n",
    "    #     # mlflow.autolog(log_models = True)\n",
    "    #     mlflow.log_params(params)\n",
    "    #     mlflow.log_metrics(eval_results)\n",
    "\n",
    "    # models[target_user] = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, ground_truth, groups, _ = DatasetLoader(dataset_name).load_data_for_training(window_shift = WINDOW_SHIFT, window_size = WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(target_metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.3\n",
    "\n",
    "for user_id in tasks_indices.keys():\n",
    "    print('-------------- {} --------------'.format(user_id))\n",
    "    train_X, test_X = [], []\n",
    "    train_Y, test_Y = [], []\n",
    "    for task_id, indices in tasks_indices[user_id].items():\n",
    "        # if user_id in ['nvtu', 'pmnguyet', 'cgurrin', 'tlduyen', 'lzhou', 'ltkhiem', 'qmboi', 'ntnhu']:\n",
    "        #     if task_id not in ['Baseline', 'Reading1', 'stest_Hard']:\n",
    "        #         continue\n",
    "        # elif user_id in ['nmduy', 'lttnga']:\n",
    "        #     if task_id not in ['Baseline', 'Reading2', 'stest_Hard']:\n",
    "        #         continue\n",
    "        # elif user_id in ['tkvan']:\n",
    "        #     if task_id not in ['Baseline', 'Reading3', 'stest_Hard']:\n",
    "        #         continue\n",
    "         \n",
    "        # if task_id in ['Baseline', 'Reading1', 'Reading2', 'Reading3', 'stest_Hard']:\n",
    "        if 1 == 1:\n",
    "            index = (1 - len(indices) * TEST_SIZE)\n",
    "            train_indices = indices[:int(index)]\n",
    "            test_indices = indices[int(index):]\n",
    "            train_X.append(dataset[train_indices, :])\n",
    "            test_X.append(dataset[test_indices, :])\n",
    "\n",
    "            # train_Y.append(ground_truth[train_indices])\n",
    "            # test_Y.append(ground_truth[test_indices])\n",
    "            if task_id in ['stest_Easy', 'stest_Medium']:\n",
    "                train_Y.append([0] * len(ground_truth[train_indices]))\n",
    "                test_Y.append([0] * len(ground_truth[test_indices]))\n",
    "            else:\n",
    "                train_Y.append(ground_truth[train_indices])\n",
    "                test_Y.append(ground_truth[test_indices])\n",
    "            \n",
    "        # elif task_id in ['Reading2', 'Reading3']:\n",
    "        #     test_X.append(dataset[indices, :])\n",
    "        #     test_Y.append(ground_truth[indices])\n",
    "        # elif task_id in ['stest_Medium']:\n",
    "        #     test_X.append(dataset[indices, :])\n",
    "        #     test_Y.append([0] * len(indices))\n",
    "        # elif task_id in ['Reading1']:\n",
    "        #     # X, y = dataset[indices, :], ground_truth[indices]\n",
    "        #     # print(task_id, min(indices), max(indices))\n",
    "        #     # new_X.append(X)\n",
    "        #     # new_y.append(y)\n",
    "        #     train_X.append(dataset[indices, :])\n",
    "        #     train_Y.append(ground_truth[indices])\n",
    "        # elif task_id in ['stest_Hard']:\n",
    "        #     test_X.append(dataset[indices, :])\n",
    "        #     test_Y.append(ground_truth[indices])\n",
    "\n",
    "    # new_X = np.concatenate(new_X, axis=0)\n",
    "    # new_y = np.concatenate(new_y, axis=0)\n",
    "\n",
    "    X_train = np.concatenate(train_X, axis=0)\n",
    "    X_test = np.concatenate(test_X, axis=0)\n",
    "    y_train = np.concatenate(train_Y, axis=0)\n",
    "    y_test = np.concatenate(test_Y, axis=0)\n",
    " #\n",
    "    train_embedding_dl = EmbeddingDataLoader(X_train, y_train)\n",
    "    validate_embedding_dl = EmbeddingDataLoader(X_test, y_test)\n",
    "\n",
    "    models[user_id].train(train_embedding_dl, validate_embedding_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('stress')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37ebc3d14ab14189c4eae9bca0430f788ed6f529827f083fec73cc217c56eda2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
